---
# Leave the homepage title empty to use the site title
title:
date: 2022-10-24
type: landing

sections:
  - block: contact
    content:

      text: |-

        <head>
          <meta charset="UTF-8" />
          <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
          <title>MediaX Lab @ SJTU</title>
          <style>
            body {
              font-family: Arial, sans-serif;
              line-height: 1.6;
              margin: 0;
              padding: 40px;
              background-color: #ffffff;
              color: #333333;
            }
            p {  
                font-size: 20px;  
            }  
            h1, h2, h3 {
              color: #1a1a1a;
            }
            h1 {
              font-size: 38px;
              margin-bottom: 20px;
            }
            h2 {
              font-size: 27px;
              margin-top: 40px;
            }
            ul {
              font-size: 20px;
              margin: 10px 0 20px 20px;
            }
            .highlight {
              color: #c0392b;
              font-weight: bold;
            }
          </style>
        </head>
        <body>

          <h1><strong>Welcome to MediaX@SJTU (ä¸Šäº¤æ™ºèƒ½åª’ä½“ç»„)</strong></h1>

          <p>
            <strong>MediaX</strong> is a research group under the <a href="https://cmic.sjtu.edu.cn/CN/Default.aspx">Cooperative Medianet Innovation Center</a> at Shanghai Jiao Tong University, focusing on cutting-edge research at the intersection of computer vision, <span class="highlight">computer vision</span>, <span class="highlight">machine learning</span>, and <span class="highlight">generative intelligent media</span>. We aim to advance the frontiers of multi-modal media (2D/3D/4D) across generation, restoration and enhancement, reconstruction and compression, and quality assessment. Our mission is to build intelligent systems capable of understanding, modeling, and manipulating complex human-centric visual content, enabling the high-quality and efficient creation of next-generation intelligent media.
          </p>

          <h2>ğŸ¯ Research Focus</h2>

          <ul>
            <li>
              <strong>Media Perception & Quality Assessment</strong><br/>
              Developing intelligent, multi-dimensional evaluation systems for UGC, PGC, and AIGC content.
            </li>
            <li>
              <strong>Video Restoration & Generation</strong><br/>
              Enhancing, controllably generating and editing 4K/8K video content.
            </li>
            <li>
              <strong>3D/4D Reconstruction & Generation</strong><br/>
              Leveraging 3DGS and GenAI for efficient representation and compression of immersive dynamic scenes.
            </li>
            <li>
              <strong>Intelligent Media Creation Platform</strong><br/>
              Building collaborative, multi-agent systems for automated and interactive media production.
            </li>
          </ul>

          <h2>ğŸ“¢ Join Us</h2>
          <p>
            We are always looking for <strong>self-motivated PhD students, Master's students, and undergraduate RA</strong> to join our team.<br/>
            If you're passionate about intelligent media and generative AI, please send your <strong>CV and transcript</strong> to: <em><span class="highlight">mediax@sjtu.edu.cn</span></em>
          </p>

          <a href="mailto:mediax@sjtu.edu.cn" target="_blank">
          <i class="fas fa-envelope"></i> è”ç³»æˆ‘ä»¬
          </a>


          <a href="https://github.com/MediaX-SJTU" target="_blank">
              <i class="fab fa-github"></i> GitHub
          </a>


          <a href="https://notes.sjtu.edu.cn/s/9NKUMusdX" target="_blank">
              <i class="fab fa-weixin"></i> å¾®ä¿¡
          </a>
        </body>

    design:
        columns: '1'


  - block: contact
    content:

      text: |-

        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>News</title>
            <style>
                body {
                }
                .news-item {
                    margin: 10px 0;
                }
            </style>
        </head>
        <body>
            <h1>ğŸ”¥ News</h1>
            <div class="news-item">[2025/6]   Six papers are accepted by ICCV 2025</div>
            <div class="news-item">[2025/2]   Eight papers are accepted by CVPR 2025 (Two orals! 3.3% of the accepted papers, and two spotlights! 13.5% of the accepted papers)</div>
            <div class="news-item">[2025/1]   One paper is accepted by ICLR 2025</div>
            <div class="news-item">[2024/12]   One paper is accepted by AAAI 2025</div>
            <div class="news-item">[2024/9]   Four papers are accepted by NeurIPS 2024</div>
            <div class="news-item">[2024/7]   Five papers are accepted by ACM MM 2024 (Three orals! One oral paper was selected as Best Paper Nominees!)</div>
            <div class="news-item">[2024/7]   Three papers are accepted by ECCV 2024 (One oral)</div>
            <div class="news-item">[2024/4]   One paper is accepted by IJCAI 2024</div>
            <div class="news-item">[2024/2]   Two papers are accepted by CVPR 2024</div>
            <div class="news-item">[2023/7]   Three papers are accepted by ACM MM 2023 (Two orals!)</div>
            <div class="news-item">[2023/7]   One paper is accepted by ICCV 2023</div>
            <div class="news-item">[2023/3]   One paper is accepted by CVPR 2023</div>
            <div class="news-item">[2022/9]   One paper is accepted by NeurIPS 2022</div>
            <div class="news-item">[2022/3]   One paper is accepted by CVPR 2022</div>
        </body>
        </html>

    design:
        columns: '1'

  - block: contact
    content:

      text: |-

        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <style>
                /* å…¨å±€é‡ç½® */
                * {
                    margin: 0;
                    padding: 0;
                    box-sizing: border-box;
                    font-family: 'Arial', sans-serif;
                }

                /* æ•´ä½“å®¹å™¨ï¼šå·¦å³ä¸¤æ ï¼ˆå·¦ä¾§å›¾ç‰‡+å³ä¾§æ–‡å­—ï¼‰ */
                .container {
                    display: flex;
                    max-width: 1200px;
                    margin: 30px auto;
                    padding: 0 20px;
                    gap: 40px; /* å·¦å³é—´è· */
                    align-items: flex-start; /* é¡¶éƒ¨å¯¹é½ï¼ˆé¿å…å›¾ç‰‡é«˜åº¦å½±å“å³ä¾§å¸ƒå±€ï¼‰ */
                }

                /* ------------------- å·¦ä¾§å›¾ç‰‡å®¹å™¨ï¼ˆä»…å›¾ç‰‡ï¼‰ ------------------- */
                .left-container {
                    width: 400px; /* å›ºå®šå®½åº¦ï¼ˆå¯æ ¹æ®å›¾ç‰‡æ¯”ä¾‹è°ƒæ•´ï¼‰ */
                    border: 1px solid #e0e0e0; /* è½»å¾®è¾¹æ¡†ï¼ˆå¯é€‰ï¼Œæå‡å±‚æ¬¡æ„Ÿï¼‰ */
                    border-radius: 8px; /* åœ†è§’ï¼ˆå¯é€‰ï¼‰ */
                    overflow: hidden; /* é˜²æ­¢å›¾ç‰‡è¶…å‡ºè¾¹æ¡†ï¼ˆè‹¥æœ‰åœ†è§’ï¼‰ */
                }

                /* å·¦ä¾§å›¾ç‰‡ï¼ˆå æ»¡å®¹å™¨ï¼Œä¿æŒæ¯”ä¾‹ï¼‰ */
                .left-image {
                    width: 100%; /* å æ»¡å·¦ä¾§å®¹å™¨å®½åº¦ */
                    height: auto; /* é«˜åº¦è‡ªåŠ¨è°ƒæ•´ï¼Œé¿å…å˜å½¢ */
                    display: block; /* å»é™¤å›¾ç‰‡åº•éƒ¨é—´éš™ */
                }

                /* ------------------- å³ä¾§æ–‡å­—å®¹å™¨ï¼ˆè®ºæ–‡ä¿¡æ¯ï¼‰ ------------------- */
                .right-container {
                    flex: 1; /* å æ®å‰©ä½™å®½åº¦ï¼Œè‡ªé€‚åº” */
                    padding-top: 10px; /* ä¸å·¦ä¾§å®¹å™¨é¡¶éƒ¨å¯¹é½ï¼ˆå¯é€‰ï¼‰ */
                }

                /* è®ºæ–‡æ ‡é¢˜ï¼ˆçªå‡ºæ˜¾ç¤ºï¼‰ */
                .paper-title {
                    font-size: 1.3em;
                    font-weight: bold;
                    color: #2c3e50;
                    margin-bottom: 15px;
                    line-height: 1.3;
                }

                /* ä½œè€…åˆ—è¡¨ï¼ˆå¸¦é»‘ç‚¹æ ‡è®°ï¼‰ */
                .authors {
                    list-style-type: disc;
                    margin-left: 25px;
                    padding-left: 0;
                    font-size: 0.95em;
                    color: #34495e;
                    margin-bottom: 10px;
                }

                /* é€šè®¯ä½œè€…ï¼ˆä¸‹åˆ’çº¿çªå‡ºï¼‰ */
                .corresponding-author {
                    text-decoration: underline;
                    font-weight: 500;
                }

                /* ä¼šè®®ä¿¡æ¯ï¼ˆç°è‰²å°å­—ï¼‰ */
                .conference {
                    font-size: 0.9em;
                    color: #7f8c8d;
                    margin-bottom: 20px;
                }

                /* è®ºæ–‡/ä»£ç é“¾æ¥ï¼ˆè“è‰²ï¼‰ */
                .links a {
                    color: #3498db;
                    text-decoration: none;
                    margin-right: 20px;
                    font-size: 0.95em;
                }

                .links a:hover {
                    text-decoration: underline; /* Hoverä¸‹åˆ’çº¿ */
                }

            </style>
        </head>
        <body>
            <div class="container">
                <!-- å·¦ä¾§ï¼šä»…å•å¼ å›¾ç‰‡ï¼ˆæ— é¢å¤–å…ƒç´ ï¼‰ -->
                <div class="left-container">
                    <img src="images/4DGC.png" alt="Visual Annotation Example" class="left-image"> <!-- æ›¿æ¢ä¸ºå®é™…å›¾ç‰‡è·¯å¾„ -->
                </div>

                <!-- å³ä¾§ï¼šè®ºæ–‡æ–‡å­—å†…å®¹ï¼ˆä¿æŒä¸å˜ï¼‰ -->
                <div class="right-container">
                    <h2 class="paper-title">[CVPR Oral] Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content</h2>
                    <ul class="authors">
                        <li>Zicheng Zhang*, Tengchuan Kou*, Shushi Wang, Chunyi Li, Wei Sun, Wei Wang, Xiaoyu Li, Zongyu Wang, Xuezhi Cao, Xiongkuo Min, <span class="corresponding-author">Xiaohong Liu*</span>, Guangtao Zhai</li>
                    </ul>
                    <p class="conference">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025.</p>
                    <div class="links">
                        <a href="https://arxiv.org/" target="_blank">[Paper]</a> <!-- æ›¿æ¢ä¸ºå®é™…è®ºæ–‡é“¾æ¥ -->
                        <a href="https://github.com/" target="_blank">[Code]</a> <!-- æ›¿æ¢ä¸ºå®é™…ä»£ç é“¾æ¥ -->
                    </div>
                </div>
            </div>
        </body>
        </html>

    design:
        columns: '1'

        
  - block: collection
    content:
      title: Latest News
      subtitle:
      text:
      count: 2
      filters:
        author: ''
        category: ''
        exclude_featured: false
        publication_type: ''
        tag: ''
      offset: 0
      order: desc
      page_type: post
    design:
      view: card
      columns: '1'
  

  - block: collection
    content:
      title: Latest prints
      text: ""
      count: 5
      filters:
        folders:
          - publication
        # publication_type: 'article'
    design:
      view: citation
      columns: '1'

  - block: markdown
    content:
      title:
      subtitle:
      text: |
        {{% cta cta_link="./people/" cta_text="Meet the team â†’" %}}
    design:
      columns: '1'
---